{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure Machine Learning workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "client = MLClient.from_config(credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Credentials from Key Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.keyvault.secrets import SecretClient\n",
    "\n",
    "keyvault_uri = \"https://plato-default-key-vault.vault.azure.net/\"\n",
    "secret_client = SecretClient(vault_url=keyvault_uri, credential=credential)\n",
    "\n",
    "tenant_id = secret_client.get_secret('azure-tenant-id').value\n",
    "client_id = secret_client.get_secret('ml-client-id').value\n",
    "client_secret = secret_client.get_secret('ml-client-secret').value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Train Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output, UserIdentityConfiguration\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "identity = UserIdentityConfiguration()\n",
    "registered_model_name = \"plato-gpt-trained-model\"\n",
    "\n",
    "input_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/sam_harris_dataset/data.txt'\n",
    "input_data_type = AssetTypes.URI_FILE\n",
    "input_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "config_path = './config.json'\n",
    "config_file_type = AssetTypes.URI_FILE\n",
    "config_file_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "output_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/azureml/'\n",
    "output_data_type = AssetTypes.URI_FOLDER\n",
    "output_mode = InputOutputModes.RW_MOUNT\n",
    "\n",
    "env = 'azureml:Plato-GPT-env:4'\n",
    "\n",
    "\n",
    "# configure the command job\n",
    "cuda_job = command(\n",
    "    inputs=dict(\n",
    "        data=Input(\n",
    "            type=input_data_type,\n",
    "            path=input_path,\n",
    "            mode=input_mode\n",
    "        ),\n",
    "        config=Input(\n",
    "            type=config_file_type,\n",
    "            path=config_path,\n",
    "            mode=config_file_mode\n",
    "        ), \n",
    "        start_fresh = True,\n",
    "        tokenizer_type = 'nltk',\n",
    "\n",
    "        batch_size = 16,\n",
    "        block_size = 256,\n",
    "        max_epoch = 5000,\n",
    "        n_embd = 768,\n",
    "        n_head = 12,\n",
    "        n_layer = 14,\n",
    "        warmup_iters = 400,\n",
    "        lr_decay_iters = 4500,\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        log_out=Output(\n",
    "            type=output_data_type,\n",
    "            path=output_path,\n",
    "            output_mode=output_mode\n",
    "        ),\n",
    "    ),\n",
    "    environment_variables= {\n",
    "        'AZURE_TENANT_ID': tenant_id,\n",
    "        'AZURE_CLIENT_ID': client_id,\n",
    "        'AZURE_CLIENT_SECRET': client_secret,\n",
    "    },\n",
    "    code=\"./src\",  # location of source code\n",
    "    command=\"python train.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --config ${{inputs.config}} \\\n",
    "            --start_fresh ${{inputs.start_fresh}} \\\n",
    "            --tokenizer_type ${{inputs.tokenizer_type}} \\\n",
    "            --max_epoch ${{inputs.max_epoch}} \\\n",
    "            --batch_size ${{inputs.batch_size}} \\\n",
    "            --block_size ${{inputs.block_size}} \\\n",
    "            --n_embd ${{inputs.n_embd}} \\\n",
    "            --n_head ${{inputs.n_head}} \\\n",
    "            --n_layer ${{inputs.n_layer}} \\\n",
    "            --warmup_iters ${{inputs.warmup_iters}} \\\n",
    "            --lr_decay_iters ${{inputs.lr_decay_iters}}\",\n",
    "    environment=env,\n",
    "    compute='nv12',\n",
    "    experiment_name=\"Plato-GPT-2-NLTK\",\n",
    "    display_name=\"NLTK-Encoding-based-cuda\",\n",
    "    identity=identity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>Plato-GPT-2-NLTK</td><td>loving_flower_5ydt4prb7x</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/loving_flower_5ydt4prb7x?wsid=/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace&amp;tid=fa6d8028-c72a-4345-9bfd-b3afb43829c1\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'loving_flower_5ydt4prb7x', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/ParzivalExtrimis/Plato-GPT-2.git', 'mlflow.source.git.branch': 'azure-trainer', 'mlflow.source.git.commit': '9909e83b228ab2ad505288b2157d647c0b0b75fb', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'ab5c6c7b-44c1-486c-ac81-bf4c5738e584'}, 'print_as_yaml': True, 'id': '/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourceGroups/plato/providers/Microsoft.MachineLearningServices/workspaces/plato-workspace/jobs/loving_flower_5ydt4prb7x', 'Resource__source_path': None, 'base_path': 'c:\\\\dev\\\\ai\\\\Plato-GPT-2', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000014B3615B1D0>, 'serialize': <msrest.serialization.Serializer object at 0x0000014B36169F90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'NLTK-Encoding-based-2', 'experiment_name': 'Plato-GPT-2-NLTK', 'compute': 'CPU-Cluster', 'services': {'Tracking': {'endpoint': 'azureml://centralindia.api.azureml.ms/mlflow/v1.0/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourceGroups/plato/providers/Microsoft.MachineLearningServices/workspaces/plato-workspace?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/loving_flower_5ydt4prb7x?wsid=/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace&tid=fa6d8028-c72a-4345-9bfd-b3afb43829c1', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/sam_harris_dataset/data.txt', 'mode': 'ro_mount'}, 'config': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/526cc335d88c5c0a9457d71b9e3a54c7/config.json', 'mode': 'ro_mount'}, 'start_fresh': 'True', 'tokenizer_type': 'nltk', 'batch_size': '16', 'block_size': '512', 'max_epoch': '3000', 'n_embd': '768', 'n_head': '12', 'n_layer': '14', 'warmup_iters': '200', 'lr_decay_iters': '2500'}, 'job_outputs': {'log_out': {'type': 'uri_folder', 'path': 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/azureml/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.loving_flower_5ydt4prb7x', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3614E7D0>, 'config': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3614DE10>, 'start_fresh': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36169FD0>, 'tokenizer_type': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3616BF50>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3616B7D0>, 'block_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3616B890>, 'max_epoch': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36168B50>, 'n_embd': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B3616A850>, 'n_head': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36168490>, 'n_layer': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36168D90>, 'warmup_iters': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36168BD0>, 'lr_decay_iters': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000014B36168510>}, 'outputs': {'log_out': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000014B3616B9D0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000014B3616B490>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'loving_flower_5ydt4prb7x', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': WindowsPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000014B3615B1D0>, 'serialize': <msrest.serialization.Serializer object at 0x0000014B34E7D7D0>, 'command': 'python train.py             --data ${{inputs.data}}             --config ${{inputs.config}}             --start_fresh ${{inputs.start_fresh}}             --tokenizer_type ${{inputs.tokenizer_type}}             --max_epoch ${{inputs.max_epoch}}             --batch_size ${{inputs.batch_size}}             --block_size ${{inputs.block_size}}             --n_embd ${{inputs.n_embd}}             --n_head ${{inputs.n_head}}             --n_layer ${{inputs.n_layer}}             --warmup_iters ${{inputs.warmup_iters}}             --lr_decay_iters ${{inputs.lr_decay_iters}}', 'code': '/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourceGroups/plato/providers/Microsoft.MachineLearningServices/workspaces/plato-workspace/codes/7695fbbd-4ee4-4aa2-8646-9c4e441d3a93/versions/1', 'environment_variables': {'AZURE_TENANT_ID': 'fa6d8028-c72a-4345-9bfd-b3afb43829c1', 'AZURE_CLIENT_ID': 'e51116dc-1bbb-4414-8454-7833b7084ed3', 'AZURE_CLIENT_SECRET': 'vrc8Q~jKqxp2t2hsiRueahLXMF10htwIwepgab_u'}, 'environment': '/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourceGroups/plato/providers/Microsoft.MachineLearningServices/workspaces/plato-workspace/environments/Plato-GPT-env/versions/4', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'NLTK-Encoding-based-2', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/sam_harris_dataset/data.txt', 'mode': 'ro_mount'}, 'config': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/526cc335d88c5c0a9457d71b9e3a54c7/config.json', 'mode': 'ro_mount'}, 'start_fresh': {'type': 'string', 'default': 'True'}, 'tokenizer_type': {'type': 'string', 'default': 'nltk'}, 'batch_size': {'type': 'string', 'default': '16'}, 'block_size': {'type': 'string', 'default': '512'}, 'max_epoch': {'type': 'string', 'default': '3000'}, 'n_embd': {'type': 'string', 'default': '768'}, 'n_head': {'type': 'string', 'default': '12'}, 'n_layer': {'type': 'string', 'default': '14'}, 'warmup_iters': {'type': 'string', 'default': '200'}, 'lr_decay_iters': {'type': 'string', 'default': '2500'}}, 'outputs': {'log_out': {'type': 'uri_folder', 'path': 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/azureml/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.loving_flower_5ydt4prb7x', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://centralindia.api.azureml.ms/mlflow/v1.0/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourceGroups/plato/providers/Microsoft.MachineLearningServices/workspaces/plato-workspace?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/loving_flower_5ydt4prb7x?wsid=/subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace&tid=fa6d8028-c72a-4345-9bfd-b3afb43829c1', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000014B3615B1D0>}, 'instance_id': '35981e6a-e47a-4566-aca8-7cc1e599cdcc', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': {'type': 'user_identity'}, 'distribution': None, 'environment_variables': {'AZURE_TENANT_ID': 'fa6d8028-c72a-4345-9bfd-b3afb43829c1', 'AZURE_CLIENT_ID': 'e51116dc-1bbb-4414-8454-7833b7084ed3', 'AZURE_CLIENT_SECRET': 'vrc8Q~jKqxp2t2hsiRueahLXMF10htwIwepgab_u'}, 'environment': 'Plato-GPT-env:4', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_or_update(cuda_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Train Job ( Small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output, UserIdentityConfiguration\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "identity = UserIdentityConfiguration()\n",
    "registered_model_name = \"plato-gpt-trained-model\"\n",
    "\n",
    "input_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/sam_harris_dataset/data.txt'\n",
    "input_data_type = AssetTypes.URI_FILE\n",
    "input_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "config_path = './config.json'\n",
    "config_file_type = AssetTypes.URI_FILE\n",
    "config_file_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "output_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/azureml/'\n",
    "output_data_type = AssetTypes.URI_FOLDER\n",
    "output_mode = InputOutputModes.RW_MOUNT\n",
    "\n",
    "env = 'azureml:Plato-GPT-env:4'\n",
    "\n",
    "\n",
    "# configure the command job\n",
    "cpu_small_job = command(\n",
    "    inputs=dict(\n",
    "        data=Input(\n",
    "            type=input_data_type,\n",
    "            path=input_path,\n",
    "            mode=input_mode\n",
    "        ),\n",
    "        config=Input(\n",
    "            type=config_file_type,\n",
    "            path=config_path,\n",
    "            mode=config_file_mode\n",
    "        ), \n",
    "        start_fresh = True,\n",
    "        tokenizer_type = 'nltk',\n",
    "\n",
    "        batch_size = 16,\n",
    "        block_size = 512,\n",
    "        max_epoch = 3000,\n",
    "        n_embd = 768,\n",
    "        n_head = 12,\n",
    "        n_layer = 14,\n",
    "        warmup_iters = 200,\n",
    "        lr_decay_iters = 2500,\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        log_out=Output(\n",
    "            type=output_data_type,\n",
    "            path=output_path,\n",
    "            output_mode=output_mode\n",
    "        ),\n",
    "    ),\n",
    "    environment_variables= {\n",
    "        'AZURE_TENANT_ID': tenant_id,\n",
    "        'AZURE_CLIENT_ID': client_id,\n",
    "        'AZURE_CLIENT_SECRET': client_secret,\n",
    "    },\n",
    "    code=\"./src\",  # location of source code\n",
    "    command=\"python train.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --config ${{inputs.config}} \\\n",
    "            --start_fresh ${{inputs.start_fresh}} \\\n",
    "            --tokenizer_type ${{inputs.tokenizer_type}} \\\n",
    "            --max_epoch ${{inputs.max_epoch}} \\\n",
    "            --batch_size ${{inputs.batch_size}} \\\n",
    "            --block_size ${{inputs.block_size}} \\\n",
    "            --n_embd ${{inputs.n_embd}} \\\n",
    "            --n_head ${{inputs.n_head}} \\\n",
    "            --n_layer ${{inputs.n_layer}} \\\n",
    "            --warmup_iters ${{inputs.warmup_iters}} \\\n",
    "            --lr_decay_iters ${{inputs.lr_decay_iters}}\",\n",
    "    environment=env,\n",
    "    compute='CPU-Cluster',\n",
    "    experiment_name=\"Plato-GPT-2-NLTK\",\n",
    "    display_name=\"NLTK-Encoding-based-cpu-S\",\n",
    "    identity=identity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_or_update(cpu_small_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Train Job ( Large )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output, UserIdentityConfiguration\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "identity = UserIdentityConfiguration()\n",
    "registered_model_name = \"plato-gpt-trained-model\"\n",
    "\n",
    "input_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/sam_harris_dataset/data.txt'\n",
    "input_data_type = AssetTypes.URI_FILE\n",
    "input_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "config_path = './config.json'\n",
    "config_file_type = AssetTypes.URI_FILE\n",
    "config_file_mode = InputOutputModes.RO_MOUNT\n",
    "\n",
    "output_path = 'azureml://subscriptions/af9d95ee-d424-470c-8f1a-3540102fef9f/resourcegroups/plato/workspaces/plato-workspace/datastores/workspaceblobstore/paths/azureml/'\n",
    "output_data_type = AssetTypes.URI_FOLDER\n",
    "output_mode = InputOutputModes.RW_MOUNT\n",
    "\n",
    "env = 'azureml:Plato-GPT-env:4'\n",
    "\n",
    "\n",
    "# configure the command job\n",
    "cpu_large_job = command(\n",
    "    inputs=dict(\n",
    "        data=Input(\n",
    "            type=input_data_type,\n",
    "            path=input_path,\n",
    "            mode=input_mode\n",
    "        ),\n",
    "        config=Input(\n",
    "            type=config_file_type,\n",
    "            path=config_path,\n",
    "            mode=config_file_mode\n",
    "        ), \n",
    "        start_fresh = True,\n",
    "        tokenizer_type = 'nltk',\n",
    "\n",
    "        batch_size = 16,\n",
    "        block_size = 512,\n",
    "        max_epoch = 8000,\n",
    "        n_embd = 768,\n",
    "        n_head = 12,\n",
    "        n_layer = 14,\n",
    "        warmup_iters = 500,\n",
    "        lr_decay_iters = 7500,\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        log_out=Output(\n",
    "            type=output_data_type,\n",
    "            path=output_path,\n",
    "            output_mode=output_mode\n",
    "        ),\n",
    "    ),\n",
    "    environment_variables= {\n",
    "        'AZURE_TENANT_ID': tenant_id,\n",
    "        'AZURE_CLIENT_ID': client_id,\n",
    "        'AZURE_CLIENT_SECRET': client_secret,\n",
    "    },\n",
    "    code=\"./src\",  # location of source code\n",
    "    command=\"python train.py \\\n",
    "            --data ${{inputs.data}} \\\n",
    "            --config ${{inputs.config}} \\\n",
    "            --start_fresh ${{inputs.start_fresh}} \\\n",
    "            --tokenizer_type ${{inputs.tokenizer_type}} \\\n",
    "            --max_epoch ${{inputs.max_epoch}} \\\n",
    "            --batch_size ${{inputs.batch_size}} \\\n",
    "            --block_size ${{inputs.block_size}} \\\n",
    "            --n_embd ${{inputs.n_embd}} \\\n",
    "            --n_head ${{inputs.n_head}} \\\n",
    "            --n_layer ${{inputs.n_layer}} \\\n",
    "            --warmup_iters ${{inputs.warmup_iters}} \\\n",
    "            --lr_decay_iters ${{inputs.lr_decay_iters}}\",\n",
    "    environment=env,\n",
    "    compute='CPU-Cluster',\n",
    "    experiment_name=\"Plato-GPT-2-NLTK\",\n",
    "    display_name=\"NLTK-Encoding-based-cpu-L\",\n",
    "    identity=identity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_or_update(cpu_large_job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
